{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN and LSTM Advanced version\n",
    "\n",
    "**Audience:**\n",
    "This version of the workshop is dedicated to participants with some prior knowledge about Python, neural networks and Keras.\n",
    "\n",
    "**Purpose:**\n",
    "Provide tasks to the participant with minimal guidance. Participant has to complete the tasks.\n",
    "\n",
    "The following helper functions are provided:\n",
    "* load_data - load the data from the csv file\n",
    "* create_dataset - creates two numpy arrays with target and features. Features are lagged prices of the stock\n",
    "* out_of_time - split in train and test\n",
    "\n",
    "Overview of the tutorial:\n",
    "\n",
    "* Data Praparetion:\n",
    "  - load the data \n",
    "  - explore the target\n",
    "  - convert data to numpy array\n",
    "  - make features: lagged price\n",
    "  - split the data intro train and test \n",
    "  - normalize the data\n",
    "\n",
    "* Feed Forward Neural Network:\n",
    "    - Define the neural network input shape\n",
    "    - Define the number of neurons, layers and activation functions\n",
    "    - Define the output of the neural network\n",
    "    - Define the loss of the neural network\n",
    "    - Compile the neural network\n",
    "    - Train the neural network\n",
    "    - Keep on eye on the loss, is the model training?\n",
    "    - Plot the predictions again the real data\n",
    "    - Redo the above with different paraments and model architectures\n",
    "    \n",
    "* LSTM:\n",
    "    - Define the neural network input shape. Reminder: LSTM needs a special shape\n",
    "    - Define the number of neurons, layers and activation functions\n",
    "    - Define the output of the neural network\n",
    "    - Define the loss of the neural network\n",
    "    - Compile the neural network\n",
    "    - Train the neural network\n",
    "    - Keep on eye on the loss, is the model training?\n",
    "    - Plot the predictions again the real data\n",
    "    - Redo the above with different paraments and model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(symbol = 'SP500'):\n",
    "    data = pd.read_csv('data_stocks.csv')\n",
    "    data = data[['DATE',symbol]].sort_values(by=['DATE'])\n",
    "    return data\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def out_of_time(dataset, train_size):\n",
    "    train_size = int(len(dataset) * train_size)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "    return train, test\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward NN - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data, by default we use S&P500\n",
    "stock_data = load_data()\n",
    "\n",
    "# visualising the data\n",
    "stock_data['SP500'].plot(figsize = (15,10))\n",
    "\n",
    "# connverting data to numoy array. Hint its array with one dimention.\n",
    "stock_data = ...\n",
    "\n",
    "# normalizing the data. Remember, neural nets work better with normalized data. Hint there is already a scaler\n",
    "stock_data = ...\n",
    "\n",
    "# Split by trian and test. First 85% of the data for training and the rest is for\n",
    "# testing. Hint use helper functon\n",
    "train, test = ...\n",
    "\n",
    "# using lagged price of the stock as feature. Here look back is number of\n",
    "# previous prices to take as a feature. Hint use helper function\n",
    "X_train, Y_train = ...\n",
    "X_test, Y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward NN - Bulding the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the model.\n",
    "\n",
    "We will do a regular feedworward model, so we select model type Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define the first hidden layer in the neural network.\n",
    "We specify the shape of the input to the hidder layer and the shape of the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(..., input_dim=..., activation='...'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a second layer we simply use add method of the model here we only need to speciy the dimentions and activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(..., activation='...'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to specify the output layer of the neural network. Hint: ints a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(..., activation='...'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our architecture figured out, we need to define loss and which algorythim to use for training the model weights. Hint: it is a regression problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='...', optimizer='...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply need to fit the model on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(..., ...,epochs=.... ,validation_data=(... ,... ),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward NN - Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will plot the prediction of the model versus actual data to see how well it trained\n",
    "\n",
    "# First we need to tranform the data back to original scare\n",
    "prediction_nn = ...\n",
    "\n",
    "# Then we need to reshape the data into the correct dimention\n",
    "prediction_nn = ....\n",
    "\n",
    "# Also we need to transform the target to the ofiginal scale\n",
    "true_data = ...\n",
    "\n",
    "# And now we can plot the results\n",
    "plt.plot(prediction_nn)\n",
    "plt.plot(true_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network - Self Activities\n",
    "\n",
    " * change the number of features\n",
    " * add more layers/neurons\n",
    " * try different activation functions\n",
    " * was scaling done correct? we scaled before splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data, by default we use S&P500\n",
    "stock_data = load_data()\n",
    "\n",
    "# visualising the data\n",
    "stock_data['SP500'].plot(figsize = (15,10))\n",
    "\n",
    "# connverting data to numoy array. Hint its array with one dimention.\n",
    "stock_data = ...\n",
    "\n",
    "# normalizing the data. Remember, neural nets work better with normalized data. Hint there is already a scaler\n",
    "stock_data = ...\n",
    "\n",
    "# Split by trian and test. First 85% of the data for training and the rest is for\n",
    "# testing. Hint use helper functon\n",
    "train, test = ...\n",
    "\n",
    "# using lagged price of the stock as feature. Here look back is number of\n",
    "# previous prices to take as a feature. Hint use helper function\n",
    "X_train, Y_train = ...\n",
    "X_test, Y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the steps of the data preparation are exactly the same as in the previous part. However, LSTMs require data to be in specific shape. \n",
    "\n",
    "LSTMs require data to be a 3D array with following elements:\n",
    " * length training data -> N\n",
    " * length of sequance we want to predict -> Y_l\n",
    " * number of features -> X_l\n",
    " \n",
    "So the 3D array takes the following form: (N, Y_l, X_l)\n",
    "\n",
    "Both Train and Test should be reshaped\n",
    "\n",
    "I do advise to look into the final data and see how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "X_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Bulding the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we first initiate a model type. Here it is again sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add an LSTM cell to our model. We need to specify model input shape and number of neurons on the LSMT cell. \n",
    "\n",
    "We will be feeding one observat at a time with N features, so our input shape is: (1,N)\n",
    "\n",
    "LSTM sells are rather standardised in terms of activations functions and achitecture inside the cell. We can change number of neurons in the cell. That is done by specifying the shape for the cell. \n",
    "\n",
    "In princical you can shange the entire structure of the LSTM cell, like activation functions and such, but for that you need to use Tensor Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(..., input_shape = (... , ...)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to specify the output layer of the neural network. Hint, it is a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(..., activation='...'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our architecture figured out, we need to define loss and which algorythim to use for training the model weights. Hist, it is a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='...',loss='...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply need to fit the model on the data. Here we need to specify the number of epochs, that is the number of time neural network will go through the dataset to train. Keep in mind that LSTMs have a lot of parameters, so in genral they need a lot epochs to train properly.\n",
    "\n",
    "While model is training, keep an eye on the loss, is it decreasing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(..., ... ,epochs=... ,validation_data=(... , ...),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will plot the prediction of the model versus actual data to see how well it trained\n",
    "\n",
    "# First we need to tranform the data back to original scare\n",
    "prediction_lstm = ...\n",
    "\n",
    "# Then we need to reshape the data into the correct dimention\n",
    "prediction_lstm = ....\n",
    "\n",
    "# Also we need to transform the target to the ofiginal scale\n",
    "true_data = ....\n",
    "\n",
    "# And now we can plot the results\n",
    "plt.plot(prediction_nn)\n",
    "plt.plot(prediction_lstm)\n",
    "plt.plot(true_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Self Activities\n",
    "\n",
    " * change the number of features\n",
    " * add more neurons to LSTM\n",
    " * maybe try adding other layer after LSTM to see what you get\n",
    " * was scaling done correct? we scaled before splitting the data\n",
    " * was the results of LSTM bettwe or worse than NN? Why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
