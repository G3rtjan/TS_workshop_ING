{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ARIMA\n",
    "\n",
    "+ **A**uto **R**egressive\n",
    "+ **I**ntegrated\n",
    "+ **M**oving **A**verage\n",
    "\n",
    "One of the most widely used approaches to time series forecasting\n",
    "\n",
    "*For more information, check out [this book](https://otexts.com/fpp2/arima.html) by Prof. Rob J Hyndman*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Auto Regressive\n",
    "\n",
    "The term *auto*regression indicates that it is a regression of the variable _against itself_\n",
    "\n",
    "Thus, an autoregressive model of order $p$ can be written as:\n",
    "\n",
    "$$y_{t}=c+\\phi_{1}y_{t-1}+\\phi_{2}y_{t-2}+\\dots+\\phi_{p}y_{t-p}+\\varepsilon_{t}$$\n",
    "\n",
    "We refer to this as an **AR($p$) model**, an autoregressive model of order $p$, where $\\varepsilon_t$ is white noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Integrated\n",
    "\n",
    "Most of our useful time series theory applies only to stationary time series.\n",
    "\n",
    "_A stationary time series is one whose properties do not depend on the time at which the series is observed._\n",
    "\n",
    "Which of the following time series do you think is/are stationary:\n",
    "\n",
    "<img src=\"figures/stationary_time_series_comparison.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Integrated\n",
    "\n",
    "Some approaches to determine whether your time series is stationary or not:\n",
    "* Apply visual inspection of the time plot (as on previous slide)\n",
    "* Apply visual inspection of autocorrelation function (ACF) and/or partial autocorrelation (PACF) plots\n",
    "* Apply unit root tests, which are statistical hypothesis tests of stationarity\n",
    "\n",
    "Or you can use approaches/algorithms that do the work for you:\n",
    "* Automatic model selection based on in-sample performance (e.g. auto_arima())\n",
    "* Automatic model selection based on out-of-sample performance\n",
    "\n",
    "We will return to this topic in the **Exercises**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Integrated\n",
    "\n",
    "_Differencing is a method for transforming a non-stationary time series into a stationary one._\n",
    "\n",
    "The differenced series is the change between consecutive observations in the original series, and can be written as:\n",
    "\n",
    "$$y'_t = y_t - y_{t-1}$$\n",
    "\n",
    "The differenced series will have only $T-1$ values, since it is not possible to calculate a difference $y'_1$ for the first observation.\n",
    "\n",
    "However, for your forecast you need to reverse the differencing (called **integration**) to arrive at the forecasted values (hence the **I** in ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Moving Average\n",
    "\n",
    "Rather than using past values of the forecast variable in a regression, a moving average model uses _past forecast errors_ in a regression-like model:\n",
    "\n",
    "$$y_{t} = c + \\varepsilon_t + \\theta_{1}\\varepsilon_{t-1} + \\theta_{2}\\varepsilon_{t-2} + \\dots + \\theta_{q}\\varepsilon_{t-q}$$\n",
    "\n",
    "We refer to this as an **MA($q$) model**, a moving average model of order $q$, where $\\varepsilon_t$ is white noise.\n",
    "\n",
    "Notice that each value of $y_t$ can be thought of as a weighted moving average of the past few forecast errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ARIMA formulation\n",
    "\n",
    "If we combine differencing with autoregression and a moving average model, we obtain a non-seasonal ARIMA model:\n",
    "\n",
    "$$y'_{t} = c + \\phi_{1}y'_{t-1} + \\cdots + \\phi_{p}y'_{t-p} + \\theta_{1}\\varepsilon_{t-1} + \\cdots + \\theta_{q}\\varepsilon_{t-q} + \\varepsilon_{t}$$\n",
    "\n",
    "Where $y'_{t}$ is the differenced series (it may have been differenced more than once!) to make it stationary.\n",
    "\n",
    "We call this an **ARIMA($p$,$d$,$q$) model**, where:\n",
    "* $p$ = order of the autoregressive part\n",
    "* $d$ = degree of first differencing involved\n",
    "* $q$ = order of the moving average part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ARIMA formulation\n",
    "\n",
    "Some special cases of ARIMA($p$,$d$,$q$) models:\n",
    "\n",
    "| Special case | Formulation |\n",
    "| ----------------- | ---------------- |\n",
    "| White noise | ARIMA(0,0,0) |\n",
    "| Random walk | ARIMA(0,1,0) with no constant |\n",
    "| Random walk with drift | ARIMA(0,1,0) with a constant |\n",
    "| Autoregression | ARIMA($p$,0,0) |\n",
    "| Moving average | ARIMA(0,0,$q$) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Seasonal ARIMA models\n",
    "\n",
    "A seasonal ARIMA model is formed by including additional seasonal terms in the ARIMA models:\n",
    "\n",
    "$$ARIMA (p,d,q) (P,D,Q)_{m}$$\n",
    "\n",
    "We use __lowercase__ notation for the __non-seasonal parts__ of the model and **UPPERCASE** notation for the **SEASONAL PARTS** of the model (where $m$ = number of observations per year).\n",
    "\n",
    "The seasonal part of the model consists of terms that are similar to the non-seasonal components of the model, but involve backshifts of the seasonal period.\n",
    "\n",
    "**Basically, there are more parameters involved to be estimated :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multivariate ARIMA(X) models\n",
    "So far we've only looked at univariate formulations of ARIMA models.\n",
    "\n",
    "It is also possible to create multivariate ARIMA models, by including (exogenous) independent variables in the model:\n",
    "\n",
    "$$y_t = \\beta_0 + \\beta_1 x_{1,t} + \\beta_2 x_{2,t} + \\dots + \\beta_{k}x_{k,t} + \\eta_t$$\n",
    "\n",
    "Where each $x$ corresponds to one of $k$  independent variables and $\\eta_t$ is an ARIMA error/process as formulated previously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ARIMA model estimation\n",
    "\n",
    "Once the model order has been identified (i.e., the values of $p$, $d$, $q$, $P$, $D$, $Q$, $m$), we need to estimate the parameters $c$, $\\phi_1,\\dots,\\phi_p$, $\\theta_1,\\dots,\\theta_q$, etc.\n",
    "\n",
    "We can use **Maximum Likelihood Estimation (MLE)**:\n",
    "\n",
    "_MLE finds the values of the parameters which maximise the probability of obtaining the data that we have observed_\n",
    "\n",
    "Usually, the _log likelihood_ is reported, which we then try to maximise when finding parameter estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ARIMA forecast\n",
    "\n",
    "Once we have determined all the parameter values, we can use the ARIMA model to make:\n",
    "* Point forecasts\n",
    "* Prediction intervals (e.g. 80% and 95% confidence intervals)*\n",
    "\n",
    "For example, for the _hsales_ (monthly sales of new one-family houses in the USA) dataset:\n",
    "\n",
    "<img src=\"figures/ARIMA_example.png\" width=\"600\">\n",
    "\n",
    "*_The prediction intervals for ARIMA models are based on assumptions that the residuals are uncorrelated and normally distributed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There are two types of people ...\n",
    "\n",
    "... which each tend to prefer one of the following approaches:\n",
    "* Analytically determine the model order (p, d, q, etc.) through manual analysis\n",
    "* Use an automated approach to determine the model order (e.g. auto.arima())\n",
    "\n",
    "In the **Exercises** you will have to try both! :)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
