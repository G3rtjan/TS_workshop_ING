{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR(1) exercise - bias and overfitting\n",
    "\n",
    "> Joris de Wind (1:1 Analytics, DBNL)\n",
    "\n",
    "In this exercise you will discover that the autoregressive coefficient of a persistent AR(1) model is biased downwards. The reason is because the standard estimation procedure takes the first observation as given, and simply ignores the likelihood of this observation. The maximum likelihood or OLS procedure will take advantage of this, which leads to overfitting and a downward bias. You will need to study some simulations to build intuition why this is the case!\n",
    "\n",
    "Along the way, you will need to write functions to calculate the unconditional mean and standard deviation of an AR(1) process. Of course, you will also need to program a function to run a simulation, and last but not least you will need to run a Monte Carlo exercise to study the bias of the autoregressive coefficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "\n",
    "from math import sqrt\n",
    "from numba import jit  # see numba.pydata.org for the documentation on\n",
    "                       # Numba, which is an open source JIT compiler that\n",
    "                       # translates a subset of Python and NumPy code into\n",
    "                       # fast machine code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconditional mean and standard deviation\n",
    "\n",
    "Consider the AR(1) model:\n",
    "\n",
    "> $y_t = \\mu + \\varrho y_{t-1} + \\varepsilon_t$\n",
    "with $\\varepsilon_t \\sim N(0, \\sigma^2)$\n",
    "\n",
    "Let's define the __unconditional mean__ of $y_t$ as $E y_t = E y_{t-1} = \\mu_{y}$.$^1$ To calculate the unconditional mean, you need to take expectations on both sides of the AR(1) equation and solve for $\\mu_{y}$. In exercise 1.1 you will need to perform the algebra, and add the solution to the AR(1) class definition below.\n",
    "\n",
    "Similarly, let's define the __unconditional standard deviation__ of $y_t$ as $\\sqrt{ E(y_t - \\mu_{y})^2 } = \\sqrt { E(y_{t-1} - \\mu_{y})^2 } = \\sigma_y$. To calculate the unconditional standard deviation, you need to perform similar algebraic manipulations as for the unconditional mean, though it's a bit more tedious now. In particular, first subtract $\\mu_{y}$ from both sides of the AR(1) equation, then square both sides and take expectations, and finally solve for $\\sigma_y$. This is what you have to do in exercise 1.2!\n",
    "\n",
    "$^1$If you are unfamiliar with the concept of the unconditional distribution, first note that the conditional mean or expectation of the AR(1) process is simply $E_{t-1} y_t = \\mu + \\varrho y_{t-1}$, i.e. we use the information that we have at time _t-1_ to the best of our knowledge. However, in the case of the unconditional distribution we simply don't have such information, and this distribution has therefore a larger variance. Finally, note that if we make a forecast for many steps ahead the forecast distribution will converge to the unconditional distribution, as the current information set becomes less and less useful the further we look into the future.\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "I already defined an AR(1) class but you will need to complete the components related to the unconditional distribution:\n",
    "\n",
    "1. Derive the formula for the unconditional mean & complete the method *calculate_unconditional_mean()*\n",
    "2. Derive the formula for the unconditional standard deviation & complete the method *calculate_unconditional_std()*\n",
    "3. Note that these methods are used to calculate the 95% confidence interval, make sure you understand this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR1:\n",
    "\n",
    "    # constructor and properties\n",
    "    # ==========================\n",
    "\n",
    "    # note that this class makes use of properties and a custom printing method\n",
    "    # if you are unfamiliar with this, it's just a way to set private attributes,\n",
    "    # and for the sake of this exercise you can simply ignore the first part of\n",
    "    # the code\n",
    "\n",
    "    def __init__(self, mu, rho, sigma, suppress_stationarity_warning=False):\n",
    "        self.suppress_stationarity_warning = suppress_stationarity_warning\n",
    "        self.mu = mu\n",
    "        self.rho = rho\n",
    "        self.sigma = sigma\n",
    "\n",
    "    # mu\n",
    "    @property\n",
    "    def mu(self):\n",
    "        return self.__mu\n",
    "\n",
    "    @mu.setter\n",
    "    def mu(self, mu):\n",
    "        self.__mu = mu\n",
    "\n",
    "    # rho\n",
    "    @property\n",
    "    def rho(self):\n",
    "        return self.__rho\n",
    "\n",
    "    @rho.setter\n",
    "    def rho(self, rho):\n",
    "        if abs(rho) >= 1 and not self.suppress_stationarity_warning:\n",
    "            print(\"Warning: the AR(1) process with \\u03C1 = {} \".format(rho) + \\\n",
    "            \"is non-stationary!\\nProceed on your own risk!\\n\\n\")\n",
    "        self.__rho = rho\n",
    "\n",
    "    # sigma\n",
    "    @property\n",
    "    def sigma(self):\n",
    "        return self.__sigma\n",
    "\n",
    "    @sigma.setter\n",
    "    def sigma(self, sigma):\n",
    "        self.__sigma = sigma\n",
    "\n",
    "    # printing\n",
    "    def __str__(self):\n",
    "        str = \\\n",
    "            \"The AR(1) model has the following parameter configuration:\" + \\\n",
    "            \"\\n\\t\" + \\\n",
    "            \"y(t) = {} + {} y(t-1) + u(t)\".format(\n",
    "                self.mu, self.rho, self.sigma) + \\\n",
    "            \"\\n\\t\" + \\\n",
    "            \"u(t) ~ N(0, {}^2)\".format(self.sigma) + \\\n",
    "            \"\\n\\n\" + \\\n",
    "            \"The unconditional distribution of the AR(1) process is:\" + \\\n",
    "            \"\\n\\t\" + \\\n",
    "            \"y(t) ~ N({}, {}^2)\".format(\n",
    "                round(self.calculate_unconditional_mean(), 1),\n",
    "                round(self.calculate_unconditional_std(), 4)) + \\\n",
    "            \"\\n\\n\"\n",
    "        return str\n",
    "\n",
    "    # unconditional distribution <= exercise 1\n",
    "    # ==========================\n",
    "\n",
    "    def calculate_unconditional_mean(self):  # <= this method should be completed in exercise 1.1\n",
    "        if abs(self.rho) >= 1:\n",
    "            return float('Inf')\n",
    "        unconditional_mean = XXX\n",
    "        return unconditional_mean\n",
    "\n",
    "    def calculate_unconditional_std(self):  # <= this method should be completed in exercise 1.2\n",
    "        if abs(self.rho) >= 1:\n",
    "            return float('Inf')\n",
    "        unconditional_std = XXX\n",
    "        return unconditional_std\n",
    "\n",
    "    def calculate_confidence_interval(self, alpha=0.95):\n",
    "        if abs(self.rho) >= 1:\n",
    "            return (float('Inf'), float('Inf'))\n",
    "        al = (1 - alpha) / 2\n",
    "        ah = 1 - al\n",
    "        unconditional_mean = self.calculate_unconditional_mean()\n",
    "        unconditional_std = self.calculate_unconditional_std()\n",
    "        lower = st.norm.ppf(al, unconditional_mean, unconditional_std)\n",
    "        upper = st.norm.ppf(ah, unconditional_mean, unconditional_std)\n",
    "        return (lower, upper)\n",
    "\n",
    "    # simulate data <= exercise 2\n",
    "    # =============\n",
    "\n",
    "    @jit\n",
    "    def simulate(self, nr_of_periods=200, nr_of_simulations=1):  # <= this method should be completed in exercise 2.1\n",
    "        if abs(self.rho) >= 1:\n",
    "            print(\"Simulation of a non-starionary process is not supported!\")\n",
    "            return\n",
    "        y = np.empty((nr_of_periods+1, nr_of_simulations))\n",
    "        y[0, ] = self.calculate_unconditional_mean() + \\\n",
    "                 self.calculate_unconditional_std() * \\\n",
    "                 np.random.randn(1, nr_of_simulations)\n",
    "        XXX\n",
    "        return y\n",
    "\n",
    "    # estimate AR(1) using OLS\n",
    "    # ========================\n",
    "\n",
    "    # note that the method below is a static method, so it should be called by\n",
    "    # AR1.estimate_ar1(y), where y should be an array with the data\n",
    "    # furthermore, the method returns an AR1 object with the estimated parameters\n",
    "\n",
    "    @staticmethod\n",
    "    def estimate_ar1(y):\n",
    "        X = y[:-1]\n",
    "        X = sm.add_constant(X)\n",
    "        y = y[1:]\n",
    "        ar1_hat = sm.OLS(y, X).fit()\n",
    "        mu_hat, rho_hat = ar1_hat.params\n",
    "        sigma_hat = sqrt(ar1_hat.mse_resid)\n",
    "        return AR1(mu_hat, rho_hat, sigma_hat, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "1. Of course, a class for a time series model is not complete without a method to simulate random data. So, hurry back to the above class and complete the simulation method!\n",
    "2. After that you can play around with the AR(1) class. Make sure to understand the various components before moving to the Monte Carlo exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing around with the AR1 class\n",
    "ar1 = AR1(0.1, 0.9, 0.007)\n",
    "print(ar1)\n",
    "\n",
    "ar1.rho = 2\n",
    "print(ar1)\n",
    "\n",
    "ar1.rho = 0.9\n",
    "ys = ar1.simulate(nr_of_periods=50, nr_of_simulations=1_000)\n",
    "print(\"The shape of ys is {} by {}\\n\\n\".format(*ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo exercise - part 1\n",
    "\n",
    "1. Run a Monte Carlo simulation to count how often the first observation falls outside the 95% confidence interval. You basically need to complete the for loop.\n",
    "2. Normally, how often should an observation fall outside its the 95% confidence interval?\n",
    "3. Can you explain the discrepancy? Don't worry if you can't explain it yet, you will build the intuition in the remainder of this exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo exercise\n",
    "T = 50\n",
    "M = 10_000\n",
    "rho = 0.95\n",
    "ar1 = AR1(0, rho, 0.01)\n",
    "np.random.seed(973)\n",
    "ys = ar1.simulate(nr_of_periods=T, nr_of_simulations=M)\n",
    "rs = np.zeros(M)\n",
    "count = 0\n",
    "for i in range(M):\n",
    "    y = ys[:, i]\n",
    "    XXX\n",
    "\n",
    "print(\"The percentage of Monte Carlo samples in which the first observation\" + \\\n",
    "\" falls\\noutside the 95% confidence interval is:\\n\\t{}%\\n\\n\".format(\n",
    "    round(100 * count / M, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo exercise - part 2\n",
    "\n",
    "1. Go back to the for loop of your Monte Carlo simulation, and save the estimated autoregressive coefficients in the vector rs.\n",
    "2. After that you can plot a histogram of the estimated autoregressive coefficients versus the true value.\n",
    "3. Can you explain the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(rs, bins=25, color='r')\n",
    "plt.axvline(x=rho, color='k', linewidth=6)\n",
    "plt.title(r\"Downward bias of $\\rho$\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(r\"$\\rho$\", fontsize=14)\n",
    "plt.show()\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo exercise - part 3\n",
    "\n",
    "In this exercise you don't need any programming, but you are challenged to build the intuition for the plot you can generate with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols, nrows = 9, 6\n",
    "fig, axs = plt.subplots(ncols, nrows, sharex=True, sharey=False,\n",
    "                        figsize=(24, 16))\n",
    "for i in range(ncols):\n",
    "    for j in range(nrows):\n",
    "        y = ys[:, i * ncols + j]\n",
    "        (lower, upper) = AR1.estimate_ar1(y).calculate_confidence_interval()\n",
    "        axs[i, j].plot(y, color='red', linewidth=3)\n",
    "        axs[i, j].axhline(lower, linestyle='--', color='k', linewidth=2)\n",
    "        axs[i, j].axhline(upper, linestyle='--', color='k', linewidth=2)\n",
    "fig.suptitle(\"Simulated data together with 95% confidence bounds\",\n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
